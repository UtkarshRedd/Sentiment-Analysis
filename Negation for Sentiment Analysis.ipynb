{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dab2282",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\utkar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import twitter_samples, stopwords, wordnet\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist, classify, NaiveBayesClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import re, string, random\n",
    "import math\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "import re\n",
    "import string\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0508097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'nasty']\n"
     ]
    }
   ],
   "source": [
    "sentence = word_tokenize(\"This is not nice\")\n",
    "for i in range(len(sentence)):\n",
    "        if sentence[i-1] in ['not',\"n't\",\"non\"]:\n",
    "            antonyms = []\n",
    "            for syn in wordnet.synsets(sentence[i]):\n",
    "                syns = wordnet.synsets(sentence[i])\n",
    "                w1 = syns[0].name()\n",
    "                for l in syn.lemmas():\n",
    "                    #synonyms.append(l.name())\n",
    "                    if l.antonyms():\n",
    "                        antonyms.append(l.antonyms()[0].name())\n",
    "                        #sentence.pop(i-1) # If the antonym of the word ahead negation exists then pop the negation and replace the word ahead with antonym\n",
    "                max_dissimilarity = 0     #If antonym does not exist then leave it alone.\n",
    "                for ant in antonyms:\n",
    "                    syns = wordnet.synsets(ant)\n",
    "                    w2 = syns[0].name()\n",
    "                    syns = wordnet.synsets(sentence[i])\n",
    "                    w1 = syns[0].name()\n",
    "                    word1 = wordnet.synset(w1)\n",
    "                    word2 = wordnet.synset(w2)\n",
    "                \n",
    "                    temp = 1 - word1.wup_similarity(word2) #Replacing with the antonym that has the maximum level of dissimilarity as per the wordnet in nltk\n",
    "                    if temp>max_dissimilarity:\n",
    "                        #print(temp)\n",
    "                        max_dissimilarity = temp\n",
    "                        antonym_max = ant\n",
    "                        sentence[i] = antonym_max\n",
    "                        sentence[i-1] = ''\n",
    "    #print(sentence)\n",
    "while '' in sentence:\n",
    "    sentence.remove('')\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "920bb842",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Negation(sentence):\n",
    "    for i in range(len(sentence)):\n",
    "        if sentence[i-1] in ['not',\"n't\",'Not','NOT']:\n",
    "            antonyms = []\n",
    "            for syn in wordnet.synsets(sentence[i]):\n",
    "                syns = wordnet.synsets(sentence[i])\n",
    "                w1 = syns[0].name()\n",
    "                for l in syn.lemmas():\n",
    "                    #synonyms.append(l.name())\n",
    "                    if l.antonyms():\n",
    "                        antonyms.append(l.antonyms()[0].name())\n",
    "                        #sentence.pop(i-1) # If the antonym of the word ahead negation exists then pop the negation and replace the word ahead with antonym\n",
    "                max_dissimilarity = 0     #If antonym does not exist then leave it alone.\n",
    "                for ant in antonyms:\n",
    "                    syns = wordnet.synsets(ant)\n",
    "                    w2 = syns[0].name()\n",
    "                    syns = wordnet.synsets(sentence[i])\n",
    "                    w1 = syns[0].name()\n",
    "                    word1 = wordnet.synset(w1)\n",
    "                    word2 = wordnet.synset(w2)\n",
    "                    if isinstance(word1.wup_similarity(word2), float) or isinstance(word1.wup_similarity(word2), int):\n",
    "                        temp = 1 - word1.wup_similarity(word2) #Replacing with the antonym that has the maximum level of dissimilarity as per the wordnet in nltk\n",
    "                    if temp>max_dissimilarity:\n",
    "                        #print(temp)\n",
    "                        max_dissimilarity = temp\n",
    "                        antonym_max = ant\n",
    "                        sentence[i] = antonym_max\n",
    "                        sentence[i-1] = ''\n",
    "    #print(sentence)\n",
    "    while '' in sentence:\n",
    "        sentence.remove('')\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4a23446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'do', 'dislike', 'this', 'event']\n"
     ]
    }
   ],
   "source": [
    "documents = [\"I do not like this event\", \"THis is not good\", \"This will actually do. It is not so bad\"]\n",
    "tokens = [word_tokenize(sentences) for sentences in documents]\n",
    "#negated_tokens = [Negation(Lists) for Lists in tokens]\n",
    "print(Negation(tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28815954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'ugly']\n"
     ]
    }
   ],
   "source": [
    "sentence = word_tokenize(\"this is not beautiful\")\n",
    "print(Negation(sentence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
