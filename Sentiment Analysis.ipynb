{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35af19fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import twitter_samples, stopwords\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist, classify, NaiveBayesClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import re, string, random\n",
    "import math\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "import re\n",
    "import string\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0104a9c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "reviews = pd.read_csv(r\"C:\\Users\\utkar\\Desktop\\Research Paper\\amazon_reviews_sample.csv\")\n",
    "df = pd.DataFrame(reviews)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310c53d6",
   "metadata": {},
   "source": [
    "<strong><h1>THIS IS THE FINAL NEGATION FUNCTION</h1></strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6616e2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence = word_tokenize(\"THis is not good and not bad also but not good also\")\n",
    "def Negation(sentence):\n",
    "    #sentence = tokens[2]\n",
    "    for i in range(len(sentence)):\n",
    "        if sentence[i-1] in ['not',\"n't\",\"non-\"]:\n",
    "            antonyms = []\n",
    "            for syn in wordnet.synsets(sentence[i]):\n",
    "                syns = wordnet.synsets(sentence[i])\n",
    "                w1 = syns[0].name()\n",
    "                for l in syn.lemmas():\n",
    "                    #synonyms.append(l.name())\n",
    "                    if l.antonyms():\n",
    "                        antonyms.append(l.antonyms()[0].name())\n",
    "                        #sentence.pop(i-1) # If the antonym of the word ahead negation exists then pop the negation and replace the word ahead with antonym\n",
    "                max_dissimilarity = 0     #If antonym does not exist then leave it alone.\n",
    "                for ant in antonyms:\n",
    "                    syns = wordnet.synsets(ant)\n",
    "                    w2 = syns[0].name()\n",
    "                    syns = wordnet.synsets(sentence[i])\n",
    "                    w1 = syns[0].name()\n",
    "                    word1 = wordnet.synset(w1)\n",
    "                    word2 = wordnet.synset(w2)\n",
    "                \n",
    "                    temp = 1 - word1.wup_similarity(word2) #Replacing with the antonym that has the maximum level of dissimilarity as per the wordnet in nltk\n",
    "                    if temp>max_dissimilarity:\n",
    "                        #print(temp)\n",
    "                        max_dissimilarity = temp\n",
    "                        antonym_max = ant\n",
    "                        sentence[i] = antonym_max\n",
    "                        sentence[i-1] = ''\n",
    "    #print(sentence)\n",
    "    while '' in sentence:\n",
    "        sentence.remove('')\n",
    "    return sentence\n",
    "\n",
    "#print(Negation(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d8a120",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\"This is not as good as that vial\", \"THis is not good\", \"This will actually do. It is not so bad\", \"I don't like to go swimming\"]\n",
    "tokens = [word_tokenize(sentences) for sentences in documents]\n",
    "negated_tokens = [Negation(Lists) for Lists in tokens]\n",
    "print(negated_tokens)\n",
    "print(Negation(word_tokenize(\"I don't like this place\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ac7d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [word_tokenize(sentence) for sentence in df.review]\n",
    "negated_tokens = [Negation(Lists) for Lists in tokens]\n",
    "print(negated_tokens[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334afb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [' '.join(r) for r in negated_tokens]\n",
    "df['Negated']=sentences\n",
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4e77e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe17634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_document(doco):\n",
    "    punctuation = string.punctuation\n",
    "    punc_replace = ''.join([' ' for s in punctuation])\n",
    "    doco_link_clean = re.sub(r'http\\S+', '', doco)\n",
    "    doco_clean_and = re.sub(r'&\\S+', '', doco_link_clean)\n",
    "    doco_clean_at = re.sub(r'@\\S+', '', doco_clean_and)\n",
    "    doco_clean = doco_clean_at.replace('-', ' ')\n",
    "    doco_alphas = re.sub(r'\\W +', ' ', doco_clean)\n",
    "    trans_table = str.maketrans(punctuation, punc_replace)\n",
    "    doco_clean = ' '.join([word.translate(trans_table) for word in doco_alphas.split(' ')])\n",
    "    doco_clean = doco_clean.split(' ')\n",
    "    p = re.compile(r'\\s*\\b(?=[a-z\\d]*([a-z\\d])\\1{3}|\\d+\\b)[a-z\\d]+', re.IGNORECASE)\n",
    "    doco_clean = ([p.sub(\"\", x).strip() for x in doco_clean])\n",
    "    doco_clean = [word.lower() for word in doco_clean if len(word) > 2]\n",
    "    #doco_clean = ([i for i in doco_clean if i not in stop])\n",
    "    doco_clean = ([i for i in doco_clean if i.isalpha()]) # removing numeric\n",
    "    #doco_clean = ([[word for word in item if word.isalpha()] for item in doco_clean])\n",
    "#     doco_clean = [spell(word) for word in doco_clean]\n",
    "#     p = re.compile(r'\\s*\\b(?=[a-z\\d]*([a-z\\d])\\1{3}|\\d+\\b)[a-z\\d]+', re.IGNORECASE)\n",
    "    doco_clean = ([p.sub(\"\", x).strip() for x in doco_clean])\n",
    "#     doco_clean = ([spell(k) for k in doco_clean])\n",
    "    return doco_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8bac7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_document(\"I don't like this place\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b2f83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_clean = [clean_document(doc) for doc in df['Negated']]\n",
    "sentences = [' '.join(r) for r in review_clean]\n",
    "df['cleantext']=sentences\n",
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8904e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(max_features = 5000)\n",
    "vect.fit(df.cleantext)\n",
    "vect_bow = vect.transform(df.cleantext)\n",
    "vect_df = pd.DataFrame(vect_bow.toarray(), columns = vect.get_feature_names())\n",
    "vect_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca04466",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.score\n",
    "X_bow = vect_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e10151",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_bow, y, test_size = 0.2, random_state = 123)\n",
    "log_reg = LogisticRegression(solver = 'lbfgs', max_iter = 1000000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_predicted = log_reg.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predicted))\n",
    "#So BOW-unigrams, preprocessing, 5000 features -> 84.25%\n",
    "#After new Negation Function -> 85.2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99720a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for tfidf\n",
    "vect1 = TfidfVectorizer(max_features = 5000)\n",
    "vect1.fit(df.cleantext)\n",
    "vect1_tfidf = vect1.transform(df.cleantext)\n",
    "vect1_df = pd.DataFrame(vect1_tfidf.toarray(), columns = vect1.get_feature_names())\n",
    "vect1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40de3b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.score\n",
    "X_tfidf = vect1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1d610f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size = 0.2, random_state = 123)\n",
    "log_reg = LogisticRegression(solver = 'lbfgs', max_iter = 1000000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_predicted = log_reg.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predicted))\n",
    "#So TFIDF-unigrams, preprocessing, 5000 features -> 85.35%\n",
    "#After new Negation function -> 87.3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7731a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing for BOW, uni+bigrams\n",
    "vect = CountVectorizer(max_features = 10000, ngram_range=(1,2))\n",
    "vect.fit(df.cleantext)\n",
    "vect_bow = vect.transform(df.cleantext)\n",
    "vect_df = pd.DataFrame(vect_bow.toarray(), columns = vect.get_feature_names())\n",
    "vect_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f766fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.score\n",
    "X_bow = vect_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210bb6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_bow, y, test_size = 0.2, random_state = 123)\n",
    "log_reg = LogisticRegression(solver = 'lbfgs', max_iter = 1000000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_predicted = log_reg.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predicted))\n",
    "#So BOW-unigrams+bigrams, preprocessing, 5000 features -> 85.15%\n",
    "#So upon doubling the no. of features the accuracy -> 85.2%. Accuracy increases exactly by .05% in both TFIDF and BOW\n",
    "#After new Negation function -> 87.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112dbfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing for BOW only bigrams\n",
    "vect = CountVectorizer(max_features = 5000, ngram_range=(2,2))\n",
    "vect.fit(df.cleantext)\n",
    "vect_bow = vect.transform(df.cleantext)\n",
    "vect_df = pd.DataFrame(vect_bow.toarray(), columns = vect.get_feature_names())\n",
    "vect_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9293e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.score\n",
    "X_bow = vect_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8b7667",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_bow, y, test_size = 0.2, random_state = 123)\n",
    "log_reg = LogisticRegression(solver = 'lbfgs', max_iter = 1000000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_predicted = log_reg.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predicted))\n",
    "#So BOW-only bigrams, preprocessing, 5000 features -> 76.7% ; The accuracy drops from uni+bigrams\n",
    "#After new Negation Function -> 81.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080c504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TFIDF testing for uni+bi\n",
    "vect1 = TfidfVectorizer(max_features = 10000, ngram_range = (1,2))\n",
    "vect1.fit(df.cleantext)\n",
    "vect1_tfidf = vect1.transform(df.cleantext)\n",
    "vect1_df = pd.DataFrame(vect1_tfidf.toarray(), columns = vect1.get_feature_names())\n",
    "vect1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1f13fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.score\n",
    "X_tfidf = vect1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa90f527",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size = 0.2, random_state = 123)\n",
    "log_reg = LogisticRegression(solver = 'lbfgs', max_iter = 1000000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_predicted = log_reg.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predicted))\n",
    "#So TFIDF-uni+bi, preprocessing, 5000 features -> 86.35%\n",
    "#In 10000 features the accuracy -> 86.4%. So upon doubling the no. of features there isnt considerable change in accuracy.\n",
    "#Accuracy increases exactly by .05% in both TFIDF and BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2a599a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing for TFIDF only bi\n",
    "vect1 = TfidfVectorizer(max_features = 5000, ngram_range = (2,2))\n",
    "vect1.fit(df.cleantext)\n",
    "vect1_tfidf = vect1.transform(df.cleantext)\n",
    "vect1_df = pd.DataFrame(vect1_tfidf.toarray(), columns = vect1.get_feature_names())\n",
    "vect1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304f360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.score\n",
    "X_tfidf = vect1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f25741e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size = 0.2, random_state = 123)\n",
    "log_reg = LogisticRegression(solver = 'lbfgs', max_iter = 1000000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_predicted = log_reg.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predicted))\n",
    "#So TFIDF-only bi, preprocessing, 5000 features -> 77.15% accuracy drops a lot from uni+bi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
